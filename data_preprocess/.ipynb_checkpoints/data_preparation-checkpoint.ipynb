{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, shutil, time, re\n",
    "import scipy.ndimage as snd\n",
    "import h5py\n",
    "import SimpleITK as sitk\n",
    "import skimage.morphology as morph\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "import cv2\n",
    "import time\n",
    "import cPickle as pickle\n",
    "# For ROI extraction\n",
    "import skimage.transform\n",
    "from scipy.fftpack import fftn, ifftn\n",
    "from skimage.feature import peak_local_max, canny\n",
    "from skimage.transform import hough_circle \n",
    "# Nifti processing\n",
    "import nibabel as nib\n",
    "from collections import OrderedDict\n",
    "# print sys.path\n",
    "# sys.path.append(\"..\") \n",
    "from IPython.display import HTML\n",
    "# Heart Metrics: TODO\n",
    "import errno\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "# Seed\n",
    "SEED=42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy(src, dest):\n",
    "  \"\"\"\n",
    "  Copy function\n",
    "  \"\"\"\n",
    "  try:\n",
    "      shutil.copytree(src, dest, ignore=shutil.ignore_patterns())\n",
    "  except OSError as e:\n",
    "      # If the error was caused because the source wasn't a directory\n",
    "      if e.errno == errno.ENOTDIR:\n",
    "          shutil.copy(src, dest)\n",
    "      else:\n",
    "          print('Directory not copied. Error: %s' % e)\n",
    "\n",
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage: \n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roi(data4D, roi_center, roi_radii):\n",
    "    \"\"\"\n",
    "    Do the animation of full heart volume\n",
    "    \"\"\"\n",
    "    x_roi_center, y_roi_center = roi_center[0], roi_center[1]\n",
    "    x_roi_radius, y_roi_radius = roi_radii[0], roi_radii[1]\n",
    "    print 'nslices', data4D.shape[2]\n",
    "\n",
    "    zslices = data4D.shape[2]\n",
    "    tframes = data4D.shape[3]\n",
    "\n",
    "    slice_cnt = 0\n",
    "    for slice in [data4D[:,:,z,:] for z in range(zslices)]:\n",
    "      outdata = np.swapaxes(np.swapaxes(slice[:,:,:], 0,2), 1,2)\n",
    "      roi_mask = np.zeros_like(outdata[0])\n",
    "      roi_mask[x_roi_center - x_roi_radius:x_roi_center + x_roi_radius,\n",
    "      y_roi_center - y_roi_radius:y_roi_center + y_roi_radius] = 1\n",
    "\n",
    "      outdata[:, roi_mask > 0.5] = 0.8 * outdata[:, roi_mask > 0.5]\n",
    "      outdata[:, roi_mask > 0.5] = 0.8 * outdata[:, roi_mask > 0.5]\n",
    "\n",
    "      fig = plt.figure(1)\n",
    "      fig.canvas.set_window_title('slice_No' + str(slice_cnt))\n",
    "      slice_cnt+=1\n",
    "      def init_out():\n",
    "          im.set_data(outdata[0])\n",
    "\n",
    "      def animate_out(i):\n",
    "          im.set_data(outdata[i])\n",
    "          return im\n",
    "\n",
    "      im = fig.gca().imshow(outdata[0], cmap='gray')\n",
    "      anim = animation.FuncAnimation(fig, animate_out, init_func=init_out, frames=tframes, interval=50)\n",
    "      anim.save('Cine_MRI_SAX_%d.mp4'%slice_cnt, fps=50, extra_args=['-vcodec', 'libx264'])\n",
    "      plt.show()\n",
    "        \n",
    "def plot_4D(data4D):\n",
    "    \"\"\"\n",
    "    Do the animation of full heart volume\n",
    "    \"\"\"\n",
    "    print 'nslices', data4D.shape[2]\n",
    "    zslices = data4D.shape[2]\n",
    "    tframes = data4D.shape[3]\n",
    "\n",
    "    slice_cnt = 0\n",
    "    for slice in [data4D[:,:,z,:] for z in range(zslices)]:\n",
    "      outdata = np.swapaxes(np.swapaxes(slice[:,:,:], 0,2), 1,2)\n",
    "      fig = plt.figure(1)\n",
    "      fig.canvas.set_window_title('slice_No' + str(slice_cnt))\n",
    "      slice_cnt+=1\n",
    "      def init_out():\n",
    "          im.set_data(outdata[0])\n",
    "\n",
    "      def animate_out(i):\n",
    "          im.set_data(outdata[i])\n",
    "          return im\n",
    "\n",
    "      im = fig.gca().imshow(outdata[0], cmap='gray')\n",
    "      anim = animation.FuncAnimation(fig, animate_out, init_func=init_out, frames=tframes, interval=50)\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "def multilabel_split(image_tensor):\n",
    "    \"\"\"\n",
    "    image_tensor : Batch * H * W\n",
    "    Split multilabel images and return stack of images\n",
    "    Returns: Tensor of shape: Batch * H * W * n_class (4D tensor)\n",
    "    # TODO: Be careful: when using this code: labels need to be \n",
    "    defined, explictly before hand as this code does not handle\n",
    "    missing labels\n",
    "    So far, this function is okay as it considers full volume for\n",
    "    finding out unique labels\n",
    "    \"\"\"\n",
    "    labels = np.unique(image_tensor)\n",
    "    batch_size = image_tensor.shape[0]\n",
    "    out_shape =  image_tensor.shape + (len(labels),)\n",
    "    image_tensor_4D = np.zeros(out_shape, dtype='uint8')\n",
    "    for i in xrange(batch_size):\n",
    "        cnt = 0\n",
    "        shape =image_tensor.shape[1:3] + (len(labels),)\n",
    "        temp = np.ones(shape, dtype='uint8')\n",
    "        for label in labels:\n",
    "            temp[...,cnt] = np.where(image_tensor[i] == label, temp[...,cnt], 0)\n",
    "            cnt += 1\n",
    "        image_tensor_4D[i] = temp\n",
    "    return image_tensor_4D\n",
    "\n",
    "def save_data(data, filename, out_path):\n",
    "    out_filename = os.path.join(out_path, filename)\n",
    "    with open(out_filename, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print 'saved to %s' % out_filename\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path) as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Hough Transform Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_roi(data4D, pixel_spacing, minradius_mm=15, maxradius_mm=45, kernel_width=5, \n",
    "                center_margin=8, num_peaks=10, num_circles=20, radstep=2):\n",
    "    \"\"\"\n",
    "    Returns center and radii of ROI region in (i,j) format\n",
    "    \"\"\"\n",
    "    # Data shape: \n",
    "    # radius of the smallest and largest circles in mm estimated from the train set\n",
    "    # convert to pixel counts\n",
    "\n",
    "    pixel_spacing_X, pixel_spacing_Y, _,_ = pixel_spacing\n",
    "    minradius = int(minradius_mm / pixel_spacing_X)\n",
    "    maxradius = int(maxradius_mm / pixel_spacing_Y)\n",
    "\n",
    "    ximagesize = data4D.shape[0]\n",
    "    yimagesize = data4D.shape[1]\n",
    "    zslices = data4D.shape[2]\n",
    "    tframes = data4D.shape[3]\n",
    "    xsurface = np.tile(range(ximagesize), (yimagesize, 1)).T\n",
    "    ysurface = np.tile(range(yimagesize), (ximagesize, 1))\n",
    "    lsurface = np.zeros((ximagesize, yimagesize))\n",
    "\n",
    "    allcenters = []\n",
    "    allaccums = []\n",
    "    allradii = []\n",
    "\n",
    "    for slice in range(zslices):\n",
    "        ff1 = fftn([data4D[:,:,slice, t] for t in range(tframes)])\n",
    "        fh = np.absolute(ifftn(ff1[1, :, :]))\n",
    "        fh[fh < 0.1 * np.max(fh)] = 0.0\n",
    "        image = 1. * fh / np.max(fh)\n",
    "#         plt.imshow(image, cmap = 'gray')\n",
    "#         plt.show()\n",
    "        # find hough circles and detect two radii\n",
    "        edges = canny(image, sigma=3)\n",
    "        # plt.imshow(edges, cmap = 'gray')\n",
    "        # plt.show()\n",
    "        hough_radii = np.arange(minradius, maxradius, radstep)\n",
    "        # print hough_radii\n",
    "        hough_res = hough_circle(edges, hough_radii)\n",
    "        # print hough_res.shape\n",
    "#         plt.imshow(hough_res[0,:,:], cmap = 'gray')\n",
    "#         plt.show()                                \n",
    "        if hough_res.any():\n",
    "            centers = []\n",
    "            accums = []\n",
    "            radii = []\n",
    "\n",
    "            for radius, h in zip(hough_radii, hough_res):\n",
    "                # For each radius, extract num_peaks circles\n",
    "                peaks = peak_local_max(h, num_peaks=num_peaks)\n",
    "                centers.extend(peaks)\n",
    "                accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
    "                radii.extend([radius] * num_peaks)\n",
    "  \n",
    "            # Keep the most prominent num_circles circles\n",
    "            sorted_circles_idxs = np.argsort(accums)[::-1][:num_circles]\n",
    "\n",
    "            for idx in sorted_circles_idxs:\n",
    "                center_x, center_y = centers[idx]\n",
    "                allcenters.append(centers[idx])\n",
    "                allradii.append(radii[idx])\n",
    "                allaccums.append(accums[idx])\n",
    "                brightness = accums[idx]\n",
    "                lsurface = lsurface + brightness * np.exp(\n",
    "                    -((xsurface - center_x) ** 2 + (ysurface - center_y) ** 2) / kernel_width ** 2)\n",
    "\n",
    "    lsurface = lsurface / lsurface.max()\n",
    "#     plt.imshow(lsurface, cmap = 'gray')\n",
    "#     plt.show() \n",
    "    # select most likely ROI center\n",
    "    roi_center = np.unravel_index(lsurface.argmax(), lsurface.shape)\n",
    "\n",
    "    # determine ROI radius\n",
    "    roi_x_radius = 0\n",
    "    roi_y_radius = 0\n",
    "    for idx in range(len(allcenters)):\n",
    "        xshift = np.abs(allcenters[idx][0] - roi_center[0])\n",
    "        yshift = np.abs(allcenters[idx][1] - roi_center[1])\n",
    "        if (xshift <= center_margin) & (yshift <= center_margin):\n",
    "            roi_x_radius = np.max((roi_x_radius, allradii[idx] + xshift))\n",
    "            roi_y_radius = np.max((roi_y_radius, allradii[idx] + yshift))\n",
    "\n",
    "    if roi_x_radius > 0 and roi_y_radius > 0:\n",
    "        roi_radii = roi_x_radius, roi_y_radius\n",
    "    else:\n",
    "        roi_radii = None\n",
    "\n",
    "#     Uncomment to plot ROI\n",
    "#     for i in range(data4D.shape[2]):    \n",
    "#         plt.imshow(data4D[:,:,i,0].T, cmap='gray')\n",
    "#         plt.plot([roi_center[0]], [roi_center[1]], marker='+', markersize=6, color=\"red\")\n",
    "#         # circle1 = plt.Circle(roi_center, roi_radii[0], color='r', fill=False)\n",
    "#         # circle2 =plt.Circle(roi_center, roi_radii[1], color='r', fill=False)\n",
    "#         ax = plt.gca()\n",
    "#         # ax.add_artist(circle1)\n",
    "#         # ax.add_artist(circle2)\n",
    "#         # Create a Rectangle patch\n",
    "#         rect = patches.Rectangle((roi_center[0]-64, roi_center[1]-64), 128,128,linewidth=1,edgecolor='r',facecolor='none')\n",
    "#         # Add the patch to the Axes\n",
    "#         ax.add_patch(rect)\n",
    "#         plt.show('roi{}'.format(i))\n",
    "        \n",
    "    return roi_center, roi_radii\n",
    "\n",
    "def extract_roi_plotter(data4D, pixel_spacing, minradius_mm=10, maxradius_mm=50, kernel_width=5, center_margin=8, num_peaks=4,\n",
    "                num_circles=8, radstep=2):\n",
    "    \"\"\"\n",
    "    Returns center and radii of ROI region in (i,j) format\n",
    "    \"\"\"\n",
    "    # Data shape: \n",
    "    # radius of the smallest and largest circles in mm estimated from the train set\n",
    "    # convert to pixel counts\n",
    "\n",
    "    pixel_spacing_X, pixel_spacing_Y, _,_ = pixel_spacing\n",
    "    minradius = int(minradius_mm / pixel_spacing_X)\n",
    "    maxradius = int(maxradius_mm / pixel_spacing_Y)\n",
    "\n",
    "    ximagesize = data4D.shape[0]\n",
    "    yimagesize = data4D.shape[1]\n",
    "    zslices = data4D.shape[2]\n",
    "    tframes = data4D.shape[3]\n",
    "    xsurface = np.tile(range(ximagesize), (yimagesize, 1)).T\n",
    "    ysurface = np.tile(range(yimagesize), (ximagesize, 1))\n",
    "    lsurface = np.zeros((ximagesize, yimagesize))\n",
    "\n",
    "    allcenters = []\n",
    "    allaccums = []\n",
    "    allradii = []\n",
    "\n",
    "    for slice in range(zslices):\n",
    "        plt.imshow(data4D[:,:,slice,0].T, cmap='gray')\n",
    "        plt.savefig('iP{}'.format(slice))\n",
    "        plt.close()\n",
    "        ff1 = fftn([data4D[:,:,slice, t] for t in range(tframes)])\n",
    "\n",
    "        plt.imshow(np.absolute(ff1[1, :, :]).T, cmap = 'gray')\n",
    "        # plt.show()\n",
    "        plt.savefig('ff1{}'.format(slice))\n",
    "        plt.close()        \n",
    "        \n",
    "        fh = np.absolute(ifftn(ff1[1, :, :]))\n",
    "        fh[fh < 0.1 * np.max(fh)] = 0.0\n",
    "        image = 1. * fh / np.max(fh)\n",
    "        plt.imshow(image.T, cmap = 'gray')\n",
    "        # plt.show()\n",
    "        plt.savefig('fh{}'.format(slice))\n",
    "        plt.close()\n",
    "\n",
    "        # find hough circles and detect two radii\n",
    "        edges = canny(image, sigma=3)\n",
    "        plt.imshow(edges.T, cmap = 'gray')\n",
    "        # plt.show()                                \n",
    "        plt.savefig('edge{}'.format(slice))\n",
    "        plt.close()\n",
    "        hough_radii = np.arange(minradius, maxradius, radstep)\n",
    "        print hough_radii\n",
    "        hough_res = hough_circle(edges, hough_radii)\n",
    "        print hough_res.shape\n",
    "        for j in range(hough_res.shape[0]):\n",
    "            plt.imshow(hough_res[j,:,:].T, cmap = 'gray')\n",
    "            # plt.show()                                \n",
    "            plt.savefig('hc{}{}'.format(slice,j))\n",
    "            plt.close()\n",
    "\n",
    "        if hough_res.any():\n",
    "            centers = []\n",
    "            accums = []\n",
    "            radii = []\n",
    "\n",
    "            for radius, h in zip(hough_radii, hough_res):\n",
    "                # For each radius, extract num_peaks circles\n",
    "                peaks = peak_local_max(h, num_peaks=num_peaks)\n",
    "                centers.extend(peaks)\n",
    "                print (h[peaks[:, 0], peaks[:, 1]])\n",
    "                print (peaks[:, 0], peaks[:, 1])\n",
    "                accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
    "                radii.extend([radius] * num_peaks)\n",
    "\n",
    "            # Keep the most prominent num_circles circles\n",
    "            print accums\n",
    "            sorted_circles_idxs = np.argsort(accums)[::-1][:num_circles]\n",
    "\n",
    "            for idx in sorted_circles_idxs:\n",
    "                center_x, center_y = centers[idx]\n",
    "                allcenters.append(centers[idx])\n",
    "                allradii.append(radii[idx])\n",
    "                allaccums.append(accums[idx])\n",
    "                brightness = accums[idx]\n",
    "                lsurface = lsurface + brightness * np.exp(\n",
    "                    -((xsurface - center_x) ** 2 + (ysurface - center_y) ** 2) / kernel_width ** 2)\n",
    "\n",
    "                plt.imshow(data4D[:,:,slice,0].T, cmap='gray')\n",
    "                plt.plot([center_x], [center_y], marker='+', markersize=5, color=\"red\")\n",
    "                circle = plt.Circle((center_x, center_y), radii[idx], color='r', fill=False)\n",
    "                ax = plt.gca()\n",
    "                ax.add_artist(circle)\n",
    "            plt.savefig('roi_peak{}'.format(slice))\n",
    "            plt.close()\n",
    "\n",
    "    lsurface = lsurface / lsurface.max()\n",
    "    plt.imshow(lsurface.T, cmap='inferno')\n",
    "    # plt.show()\n",
    "    plt.savefig('ls')\n",
    "    plt.close()\n",
    "    plt.imshow(data4D[:,:,0,0].T, cmap='gray') # interpolation='none'\n",
    "    plt.imshow(lsurface.T, cmap='nipy_spectral', alpha=0.5) # interpolation='none'\n",
    "    plt.savefig('ls_overlay_0_ed')\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(data4D[:,:,0,9].T, cmap='gray') # interpolation='none'\n",
    "    plt.imshow(lsurface.T, cmap='nipy_spectral', alpha=0.5) # interpolation='none'\n",
    "    plt.savefig('ls_overlay_0_es')\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(data4D[:,:,2,0].T, cmap='gray') # interpolation='none'\n",
    "    plt.imshow(lsurface.T, cmap='nipy_spectral', alpha=0.5) # interpolation='none'\n",
    "    plt.savefig('ls_overlay_2_ed')\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(data4D[:,:,2,9].T, cmap='gray') # interpolation='none'\n",
    "    plt.imshow(lsurface.T, cmap='nipy_spectral', alpha=0.5) # interpolation='none'\n",
    "    plt.savefig('ls_overlay_2_es')\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(data4D[:,:,8,0].T, cmap='gray') # interpolation='none'\n",
    "    plt.imshow(lsurface.T, cmap='nipy_spectral', alpha=0.5) # interpolation='none'\n",
    "    plt.savefig('ls_overlay_8_ed')\n",
    "    plt.close()\n",
    "\n",
    "    plt.imshow(data4D[:,:,8,9].T, cmap='gray') # interpolation='none'\n",
    "    plt.imshow(lsurface.T, cmap='nipy_spectral', alpha=0.5) # interpolation='none'\n",
    "    plt.savefig('ls_overlay_8_es')\n",
    "    plt.close()\n",
    "\n",
    "    # select most likely ROI center\n",
    "    roi_center = np.unravel_index(lsurface.argmax(), lsurface.shape)\n",
    "\n",
    "    # determine ROI radius\n",
    "    roi_x_radius = 0\n",
    "    roi_y_radius = 0\n",
    "    for idx in range(len(allcenters)):\n",
    "        xshift = np.abs(allcenters[idx][0] - roi_center[0])\n",
    "        yshift = np.abs(allcenters[idx][1] - roi_center[1])\n",
    "        if (xshift <= center_margin) & (yshift <= center_margin):\n",
    "            roi_x_radius = np.max((roi_x_radius, allradii[idx] + xshift))\n",
    "            roi_y_radius = np.max((roi_y_radius, allradii[idx] + yshift))\n",
    "\n",
    "    if roi_x_radius > 0 and roi_y_radius > 0:\n",
    "        roi_radii = roi_x_radius, roi_y_radius\n",
    "    else:\n",
    "        roi_radii = None\n",
    "\n",
    "    for i in range(data4D.shape[2]):    \n",
    "        plt.imshow(data4D[:,:,i,0].T, cmap='gray')\n",
    "        plt.plot([roi_center[0]], [roi_center[1]], marker='+', markersize=6, color=\"red\")\n",
    "        # circle1 = plt.Circle(roi_center, roi_radii[0], color='r', fill=False)\n",
    "        # circle2 =plt.Circle(roi_center, roi_radii[1], color='r', fill=False)\n",
    "        ax = plt.gca()\n",
    "        # ax.add_artist(circle1)\n",
    "        # ax.add_artist(circle2)\n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle((roi_center[0]-64, roi_center[1]-64), 128,128,linewidth=1,edgecolor='r',facecolor='none')\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        plt.savefig('roi{}'.format(i))\n",
    "        plt.close()\n",
    "\n",
    "    return roi_center, roi_radii\n",
    "\n",
    "def pad_to_bounding_box(image, offset_height, offset_width, target_height,\n",
    "                        target_width):\n",
    "  \"\"\"Pad `image` with zeros to the specified `height` and `width`.\n",
    "  Adds `offset_height` rows of zeros on top, `offset_width` columns of\n",
    "  zeros on the left, and then pads the image on the bottom and right\n",
    "  with zeros until it has dimensions `target_height`, `target_width`.\n",
    "  This op does nothing if `offset_*` is zero and the image already has size\n",
    "  `target_height` by `target_width`.\n",
    "  Args:\n",
    "    image: 2-D Tensor of shape `[height, width]`\n",
    "    offset_height: Number of rows of zeros to add on top.\n",
    "    offset_width: Number of columns of zeros to add on the left.\n",
    "    target_height: Height of output image.\n",
    "    target_width: Width of output image.\n",
    "  Returns:\n",
    "    If `image` was 2-D, a 2-D float Tensor of shape\n",
    "    `[target_height, target_width]`\n",
    "  Raises:\n",
    "    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n",
    "      `target_*` arguments, or either `offset_height` or `offset_width` is\n",
    "      negative.\n",
    "  \"\"\"\n",
    "  height, width = image.shape\n",
    "\n",
    "  after_padding_width = target_width - offset_width - width\n",
    "  after_padding_height = target_height - offset_height - height\n",
    "\n",
    "  assert (offset_height >= 0),\"offset_height must be >= 0\"    \n",
    "  assert (offset_width >= 0),\"width must be <= target - offset\"    \n",
    "  assert (after_padding_width >= 0),\"height must be <= target - offset\"    \n",
    "  assert (after_padding_height >= 0),\"height must be <= target - offset\"    \n",
    "\n",
    "  # Do not pad on the depth dimensions.\n",
    "  padded = np.lib.pad(image, ((offset_height, after_padding_height),\n",
    "                     (offset_width, after_padding_width)), 'symmetric')\n",
    "  return padded\n",
    "\n",
    "\n",
    "def crop_to_bounding_box(image, offset_height, offset_width, target_height,\n",
    "                         target_width):\n",
    "  \"\"\"Crops an image to a specified bounding box.\n",
    "  This op cuts a rectangular part out of `image`. The top-left corner of the\n",
    "  returned image is at `offset_height, offset_width` in `image`, and its\n",
    "  lower-right corner is at\n",
    "  `offset_height + target_height, offset_width + target_width`.\n",
    "  Args:\n",
    "    image: 2-D Tensor of shape `[height, width]`.\n",
    "    offset_height: Vertical coordinate of the top-left corner of the result in\n",
    "                   the input.\n",
    "    offset_width: Horizontal coordinate of the top-left corner of the result in\n",
    "                  the input.\n",
    "    target_height: Height of the result.\n",
    "    target_width: Width of the result.\n",
    "  Returns:\n",
    "    If `image` was 2-D, a 2-D float Tensor of shape\n",
    "    `[target_height, target_width]`\n",
    "  Raises:\n",
    "    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n",
    "      `target_*` arguments, or either `offset_height` or `offset_width` is\n",
    "      negative, or either `target_height` or `target_width` is not positive.\n",
    "  \"\"\"\n",
    "  height, width = image.shape\n",
    "\n",
    "  assert (offset_width >= 0),\"offset_width must be >= 0.\"    \n",
    "  assert (offset_height >= 0),\"offset_height must be >= 0.\"    \n",
    "  assert (target_width > 0),\"target_width must be > 0.\"    \n",
    "  assert (target_height > 0),\"target_height must be > 0.\" \n",
    "  assert (width >= (target_width + offset_width)),\"width must be >= target + offset.\"    \n",
    "  assert (height >= (target_height + offset_height)),\"height must be >= target + offset.\"    \n",
    "  cropped = image[offset_height: target_height+offset_height, offset_width: target_width+offset_width]\n",
    "  return cropped\n",
    "\n",
    "def resize_image_with_crop_or_pad(image, target_height, target_width):\n",
    "  \"\"\"Crops and/or pads an image to a target width and height.\n",
    "  Resizes an image to a target width and height by either centrally\n",
    "  cropping the image or padding it evenly with zeros.\n",
    "  If `width` or `height` is greater than the specified `target_width` or\n",
    "  `target_height` respectively, this op centrally crops along that dimension.\n",
    "  If `width` or `height` is smaller than the specified `target_width` or\n",
    "  `target_height` respectively, this op centrally pads with 0 along that\n",
    "  dimension.\n",
    "  Args:\n",
    "    image: 2-D Tensor of shape `[ height, width]` or\n",
    "    target_height: Target height.\n",
    "    target_width: Target width.\n",
    "  Raises:\n",
    "    ValueError: if `target_height` or `target_width` are zero or negative.\n",
    "  Returns:\n",
    "    Cropped and/or padded image.\n",
    "  \"\"\"\n",
    "\n",
    "  # `crop_to_bounding_box` and `pad_to_bounding_box` have their own checks.\n",
    "  def max_(x, y):\n",
    "      return max(x, y)\n",
    "\n",
    "  def min_(x, y):\n",
    "      return min(x, y)\n",
    "\n",
    "  def equal_(x, y):\n",
    "      return x == y\n",
    "\n",
    "  height, width = image.shape\n",
    "  width_diff = target_width - width\n",
    "  offset_crop_width = max_(-width_diff // 2, 0)\n",
    "  offset_pad_width = max_(width_diff // 2, 0)\n",
    "\n",
    "  height_diff = target_height - height\n",
    "  offset_crop_height = max_(-height_diff // 2, 0)\n",
    "  offset_pad_height = max_(height_diff // 2, 0)\n",
    "\n",
    "  # Maybe crop if needed.\n",
    "  cropped = crop_to_bounding_box(image, offset_crop_height, offset_crop_width,\n",
    "                                 min_(target_height, height),\n",
    "                                 min_(target_width, width))\n",
    "\n",
    "  # Maybe pad if needed.\n",
    "  resized = pad_to_bounding_box(cropped, offset_pad_height, offset_pad_width,\n",
    "                                target_height, target_width)\n",
    "\n",
    "  return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_validate_test_splits(src_path, dest_path):\n",
    "  \"\"\"\n",
    "  Split the data into 70:15:15 for train-validate-test set\n",
    "  arg: path: input data path\n",
    "  \"\"\"\n",
    "  SPLIT_TRAIN = 0.7\n",
    "  SPLIT_VALID = 0.2\n",
    "\n",
    "  dest_path = os.path.join(dest_path,'dataset')\n",
    "  if os.path.exists(dest_path):\n",
    "    shutil.rmtree(dest_path)\n",
    "  os.makedirs(os.path.join(dest_path, 'train_set'))  \n",
    "  os.makedirs(os.path.join(dest_path, 'validation_set'))  \n",
    "  os.makedirs(os.path.join(dest_path, 'test_set'))  \n",
    "  print (src_path)\n",
    "  patient_folders = next(os.walk(src_path))[1]\n",
    "  print (patient_folders)\n",
    "  np.random.shuffle(patient_folders)\n",
    "  train_ = patient_folders[0:int(SPLIT_TRAIN*len(patient_folders))]\n",
    "  valid_ = patient_folders[int(SPLIT_TRAIN*len(patient_folders)): \n",
    "               int((SPLIT_TRAIN+SPLIT_VALID)*len(patient_folders))]\n",
    "  test_ = patient_folders[int((SPLIT_TRAIN+SPLIT_VALID)*len(patient_folders)):]\n",
    "\n",
    "  for patient in train_:\n",
    "    folder_path = os.path.join(src_path, patient)\n",
    "    copy(folder_path, os.path.join(dest_path, 'train_set', patient))\n",
    "\n",
    "  for patient in valid_:\n",
    "    folder_path = os.path.join(src_path, patient)\n",
    "    copy(folder_path, os.path.join(dest_path, 'validation_set', patient))\n",
    "\n",
    "  for patient in test_:\n",
    "    folder_path = os.path.join(src_path, patient)\n",
    "    copy(folder_path, os.path.join(dest_path, 'test_set', patient)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training_data_path = '../../LV_2011_dataset/Training'\n",
    "# dest_path = '../../processed_dataset'\n",
    "# generate_train_validate_test_splits(Training_data_path, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_4D_volume(path_list):\n",
    "    #print (path_list)\n",
    "    sa_list = []\n",
    "    ph_list = [] \n",
    "    boImgSizeNotEq = False\n",
    "    ref_img_size = sitk.ReadImage(path_list[0]).GetSize()\n",
    "    # print file_list\n",
    "    for path in path_list:\n",
    "        file_name = os.path.basename(path)\n",
    "        #print re.findall(r'\\d+', file_name)\n",
    "        pat_id = re.findall(r'\\d+', file_name)[0]\n",
    "        sa = re.findall(r'\\d+', file_name)[1]\n",
    "        ph = re.findall(r'\\d+', file_name)[2]\n",
    "        if not int(sa) in sa_list:\n",
    "            sa_list.append(int(sa))\n",
    "        if not int(ph) in ph_list:\n",
    "            ph_list.append(int(ph))\n",
    "        # Check if the sizes of all slices are equal\n",
    "        img_size = sitk.ReadImage(path).GetSize()\n",
    "        if img_size != ref_img_size:\n",
    "            boImgSizeNotEq = True\n",
    "#             print ('The Sizes donot match: the image will cropped or padded to reference slice')\n",
    "    sa_list_sorted = np.sort(sa_list)\n",
    "    ph_list_sorted = np.sort(ph_list)\n",
    "    n_slices = len(sa_list_sorted)\n",
    "    n_phases = len(ph_list_sorted)\n",
    "    img = sitk.ReadImage(path_list[0])\n",
    "    img_data = sitk.GetArrayFromImage(img)\n",
    "#     print (img_data.shape)\n",
    "    x_dim, y_dim = img_data.shape[1:]      \n",
    "#     print(img.GetOrigin())\n",
    "#     print(img.GetSize())\n",
    "#     print(img.GetSpacing())\n",
    "#     print(img.GetDirection())\n",
    "    x_dim, y_dim = img_data.shape[:2]\n",
    "    pat_id = re.findall(r'\\d+', os.path.basename(path_list[0]))[0]\n",
    "    pat_dir = os.path.dirname(path_list[0])\n",
    "#     print (pat_id, pat_dir) \n",
    "    data_4d_img = np.zeros([x_dim, y_dim, n_slices, n_phases], dtype=np.uint16)\n",
    "    data_4d_gt = np.zeros([x_dim, y_dim, n_slices, n_phases], dtype=np.uint8)        \n",
    "    for slice in sa_list_sorted:\n",
    "        for phase in ph_list_sorted:\n",
    "#             print (phase, slice)\n",
    "#             Image\n",
    "            file_path = (pat_dir + \"/DET\"+pat_id+\"_SA\"+str(slice)+\"_ph\"+str(phase)+\".dcm\")\n",
    "            slice_img = sitk.ReadImage(file_path)\n",
    "            img_data = sitk.GetArrayFromImage(slice_img)   \n",
    "            data_4d_img[:,:,slice-1,phase] = resize_image_with_crop_or_pad(img_data[0,:,:], x_dim, y_dim)\n",
    "#             Label\n",
    "            file_path = (pat_dir + \"/DET\"+pat_id+\"_SA\"+str(slice)+\"_ph\"+str(phase)+\".png\")                \n",
    "            slice_img = sitk.ReadImage(file_path)\n",
    "            img_data = sitk.GetArrayFromImage(slice_img)\n",
    "            # Ground Truth Preprocessing: Threshold the image between (0,1)\n",
    "            # TODO: Generalize: The data is in .PNG format for LV 2011. So white vvalues are 255\n",
    "            img_data[np.where(img_data>0)] = 1\n",
    "            data_4d_gt[:,:,slice-1,phase] = resize_image_with_crop_or_pad(img_data[:,:,0], x_dim, y_dim)\n",
    "\n",
    "    return data_4d_img, data_4d_gt, img.GetSpacing()\n",
    "    \n",
    "def separate_LA_SA(src_path, save4D=True):\n",
    "    \"\"\"\n",
    "    Segregate the splits into LA and SA views and dump all files in a common folder\n",
    "    \"\"\"\n",
    "    train_set_path = os.path.join(src_path, 'train_set') \n",
    "    valid_set_path = os.path.join(src_path, 'validation_set') \n",
    "    test_set_path = os.path.join(src_path, 'test_set') \n",
    "\n",
    "    if os.path.exists(os.path.join(src_path, 'SA')):\n",
    "        shutil.rmtree(os.path.join(src_path, 'SA'))\n",
    "    os.makedirs(os.path.join(src_path, 'SA', os.path.basename(train_set_path))) \n",
    "    os.makedirs(os.path.join(src_path, 'SA', os.path.basename(valid_set_path))) \n",
    "    os.makedirs(os.path.join(src_path, 'SA', os.path.basename(test_set_path)))\n",
    "\n",
    "    paths = [train_set_path, valid_set_path, test_set_path]\n",
    "    for path in paths:\n",
    "        print (path)\n",
    "        patient_folders = next(os.walk(path))[1]\n",
    "        for patient in tqdm(patient_folders):\n",
    "            folder_path = os.path.join(path, patient)\n",
    "            img_file_path_list = glob.glob(folder_path + \"/*_SA*_ph*.dcm\")\n",
    "#             gt_file_path_list = glob.glob(folder_path + \"/*_SA*_ph*.png\")\n",
    "            imd_4d, gt_4d, pixel_spacing = get_4D_volume(img_file_path_list)\n",
    "            pixel_spacing += (1,) \n",
    "            c, r = extract_roi(imd_4d, pixel_spacing)\n",
    "            print (folder_path, imd_4d.shape, (c,r))\n",
    "    #         To Save as 4D-volumes\n",
    "            if save4D:\n",
    "                hp = h5py.File(os.path.join(src_path, 'SA', os.path.basename(path), patient+'.hdf5'),'w')\n",
    "                hp.create_dataset('image', data=imd_4d)\n",
    "                hp.create_dataset('label', data=gt_4d)\n",
    "                hp.create_dataset('roi_center', data=c)\n",
    "                hp.create_dataset('roi_radii', data=r)\n",
    "                hp.create_dataset('pixel_spacing', data=pixel_spacing)                \n",
    "                hp.close()\n",
    "            else:                \n",
    "    #         To Save as 2D images\n",
    "                _, _, slice_n, phase_n = imd_4d.shape\n",
    "                for slice in range(slice_n):\n",
    "                    for phase in range(phase_n):                \n",
    "                        hp = h5py.File(os.path.join(src_path, 'SA', os.path.basename(path),\n",
    "                                                    patient+\"_SA\"+str(slice)+\"_ph\"+str(phase)+'.hdf5'),'w')\n",
    "                        hp.create_dataset('image', data=imd_4d[:,:,slice, phase])\n",
    "                        hp.create_dataset('label', data=gt_4d[:,:,slice, phase])\n",
    "                        hp.create_dataset('roi_center', data=c)\n",
    "                        hp.create_dataset('roi_radii', data=r)\n",
    "                        hp.create_dataset('pixel_spacing', data=pixel_spacing)   \n",
    "                        hp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../processed_dataset/dataset/train_set\n",
      "(0, 1)\n",
      "(1, 1)\n",
      "(2, 1)\n",
      "(3, 1)\n",
      "(4, 1)\n",
      "(5, 1)\n",
      "(6, 1)\n",
      "(7, 1)\n",
      "(8, 1)\n",
      "(9, 1)\n",
      "(10, 1)\n",
      "(11, 1)\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "(15, 1)\n",
      "(16, 1)\n",
      "(17, 1)\n",
      "(18, 1)\n",
      "(19, 1)\n",
      "(20, 1)\n",
      "(21, 1)\n",
      "(22, 1)\n",
      "(23, 1)\n",
      "(24, 1)\n",
      "(25, 1)\n",
      "(26, 1)\n",
      "(27, 1)\n",
      "(28, 1)\n",
      "(29, 1)\n",
      "(0, 2)\n",
      "(1, 2)\n",
      "(2, 2)\n",
      "(3, 2)\n",
      "(4, 2)\n",
      "(5, 2)\n",
      "(6, 2)\n",
      "(7, 2)\n",
      "(8, 2)\n",
      "(9, 2)\n",
      "(10, 2)\n",
      "(11, 2)\n",
      "(12, 2)\n",
      "(13, 2)\n",
      "(14, 2)\n",
      "(15, 2)\n",
      "(16, 2)\n",
      "(17, 2)\n",
      "(18, 2)\n",
      "(19, 2)\n",
      "(20, 2)\n",
      "(21, 2)\n",
      "(22, 2)\n",
      "(23, 2)\n",
      "(24, 2)\n",
      "(25, 2)\n",
      "(26, 2)\n",
      "(27, 2)\n",
      "(28, 2)\n",
      "(29, 2)\n",
      "(0, 3)\n",
      "(1, 3)\n",
      "(2, 3)\n",
      "(3, 3)\n",
      "(4, 3)\n",
      "(5, 3)\n",
      "(6, 3)\n",
      "(7, 3)\n",
      "(8, 3)\n",
      "(9, 3)\n",
      "(10, 3)\n",
      "(11, 3)\n",
      "(12, 3)\n",
      "(13, 3)\n",
      "(14, 3)\n",
      "(15, 3)\n",
      "(16, 3)\n",
      "(17, 3)\n",
      "(18, 3)\n",
      "(19, 3)\n",
      "(20, 3)\n",
      "(21, 3)\n",
      "(22, 3)\n",
      "(23, 3)\n",
      "(24, 3)\n",
      "(25, 3)\n",
      "(26, 3)\n",
      "(27, 3)\n",
      "(28, 3)\n",
      "(29, 3)\n",
      "(0, 4)\n",
      "(1, 4)\n",
      "(2, 4)\n",
      "(3, 4)\n",
      "(4, 4)\n",
      "(5, 4)\n",
      "(6, 4)\n",
      "(7, 4)\n",
      "(8, 4)\n",
      "(9, 4)\n",
      "(10, 4)\n",
      "(11, 4)\n",
      "(12, 4)\n",
      "(13, 4)\n",
      "(14, 4)\n",
      "(15, 4)\n",
      "(16, 4)\n",
      "(17, 4)\n",
      "(18, 4)\n",
      "(19, 4)\n",
      "(20, 4)\n",
      "(21, 4)\n",
      "(22, 4)\n",
      "(23, 4)\n",
      "(24, 4)\n",
      "(25, 4)\n",
      "(26, 4)\n",
      "(27, 4)\n",
      "(28, 4)\n",
      "(29, 4)\n",
      "(0, 5)\n",
      "(1, 5)\n",
      "(2, 5)\n",
      "(3, 5)\n",
      "(4, 5)\n",
      "(5, 5)\n",
      "(6, 5)\n",
      "(7, 5)\n",
      "(8, 5)\n",
      "(9, 5)\n",
      "(10, 5)\n",
      "(11, 5)\n",
      "(12, 5)\n",
      "(13, 5)\n",
      "(14, 5)\n",
      "(15, 5)\n",
      "(16, 5)\n",
      "(17, 5)\n",
      "(18, 5)\n",
      "(19, 5)\n",
      "(20, 5)\n",
      "(21, 5)\n",
      "(22, 5)\n",
      "(23, 5)\n",
      "(24, 5)\n",
      "(25, 5)\n",
      "(26, 5)\n",
      "(27, 5)\n",
      "(28, 5)\n",
      "(29, 5)\n",
      "(0, 6)\n",
      "(1, 6)\n",
      "(2, 6)\n",
      "(3, 6)\n",
      "(4, 6)\n",
      "(5, 6)\n",
      "(6, 6)\n",
      "(7, 6)\n",
      "(8, 6)\n",
      "(9, 6)\n",
      "(10, 6)\n",
      "(11, 6)\n",
      "(12, 6)\n",
      "(13, 6)\n",
      "(14, 6)\n",
      "(15, 6)\n",
      "(16, 6)\n",
      "(17, 6)\n",
      "(18, 6)\n",
      "(19, 6)\n",
      "(20, 6)\n",
      "(21, 6)\n",
      "(22, 6)\n",
      "(23, 6)\n",
      "(24, 6)\n",
      "(25, 6)\n",
      "(26, 6)\n",
      "(27, 6)\n",
      "(28, 6)\n",
      "(29, 6)\n",
      "(0, 7)\n",
      "(1, 7)\n",
      "(2, 7)\n",
      "(3, 7)\n",
      "(4, 7)\n",
      "(5, 7)\n",
      "(6, 7)\n",
      "(7, 7)\n",
      "(8, 7)\n",
      "(9, 7)\n",
      "(10, 7)\n",
      "(11, 7)\n",
      "(12, 7)\n",
      "(13, 7)\n",
      "(14, 7)\n",
      "(15, 7)\n",
      "(16, 7)\n",
      "(17, 7)\n",
      "(18, 7)\n",
      "(19, 7)\n",
      "(20, 7)\n",
      "(21, 7)\n",
      "(22, 7)\n",
      "(23, 7)\n",
      "(24, 7)\n",
      "(25, 7)\n",
      "(26, 7)\n",
      "(27, 7)\n",
      "(28, 7)\n",
      "(29, 7)\n",
      "(0, 8)\n",
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "(11, 8)\n",
      "(12, 8)\n",
      "(13, 8)\n",
      "(14, 8)\n",
      "(15, 8)\n",
      "(16, 8)\n",
      "(17, 8)\n",
      "(18, 8)\n",
      "(19, 8)\n",
      "(20, 8)\n",
      "(21, 8)\n",
      "(22, 8)\n",
      "(23, 8)\n",
      "(24, 8)\n",
      "(25, 8)\n",
      "(26, 8)\n",
      "(27, 8)\n",
      "(28, 8)\n",
      "(29, 8)\n",
      "(0, 9)\n",
      "(1, 9)\n",
      "(2, 9)\n",
      "(3, 9)\n",
      "(4, 9)\n",
      "(5, 9)\n",
      "(6, 9)\n",
      "(7, 9)\n",
      "(8, 9)\n",
      "(9, 9)\n",
      "(10, 9)\n",
      "(11, 9)\n",
      "(12, 9)\n",
      "(13, 9)\n",
      "(14, 9)\n",
      "(15, 9)\n",
      "(16, 9)\n",
      "(17, 9)\n",
      "(18, 9)\n",
      "(19, 9)\n",
      "(20, 9)\n",
      "(21, 9)\n",
      "(22, 9)\n",
      "(23, 9)\n",
      "(24, 9)\n",
      "(25, 9)\n",
      "(26, 9)\n",
      "(27, 9)\n",
      "(28, 9)\n",
      "(29, 9)\n",
      "(0, 10)\n",
      "(1, 10)\n",
      "(2, 10)\n",
      "(3, 10)\n",
      "(4, 10)\n",
      "(5, 10)\n",
      "(6, 10)\n",
      "(7, 10)\n",
      "(8, 10)\n",
      "(9, 10)\n",
      "(10, 10)\n",
      "(11, 10)\n",
      "(12, 10)\n",
      "(13, 10)\n",
      "(14, 10)\n",
      "(15, 10)\n",
      "(16, 10)\n",
      "(17, 10)\n",
      "(18, 10)\n",
      "(19, 10)\n",
      "(20, 10)\n",
      "(21, 10)\n",
      "(22, 10)\n",
      "(23, 10)\n",
      "(24, 10)\n",
      "(25, 10)\n",
      "(26, 10)\n",
      "(27, 10)\n",
      "(28, 10)\n",
      "(29, 10)\n",
      "(0, 11)\n",
      "(1, 11)\n",
      "(2, 11)\n",
      "(3, 11)\n",
      "(4, 11)\n",
      "(5, 11)\n",
      "(6, 11)\n",
      "(7, 11)\n",
      "(8, 11)\n",
      "(9, 11)\n",
      "(10, 11)\n",
      "(11, 11)\n",
      "(12, 11)\n",
      "(13, 11)\n",
      "(14, 11)\n",
      "(15, 11)\n",
      "(16, 11)\n",
      "(17, 11)\n",
      "(18, 11)\n",
      "(19, 11)\n",
      "(20, 11)\n",
      "(21, 11)\n",
      "(22, 11)\n",
      "(23, 11)\n",
      "(24, 11)\n",
      "(25, 11)\n",
      "(26, 11)\n",
      "(27, 11)\n",
      "(28, 11)\n",
      "(29, 11)\n",
      "('../../processed_dataset/dataset/train_set/DET0001701', (1, 256, 11, 30), ((0, 0), None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "One of data, shape or dtype must be specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c83c1f40bbba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msrc_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../processed_dataset/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseparate_LA_SA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave4D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-511c24c6855a>\u001b[0m in \u001b[0;36mseparate_LA_SA\u001b[0;34m(src_path, save4D)\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt_4d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                         \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roi_center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                         \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roi_radii'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                         \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pixel_spacing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_spacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                         \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.pyc\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"One of data, shape or dtype must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: One of data, shape or dtype must be specified"
     ]
    }
   ],
   "source": [
    "src_path = '../../processed_dataset/dataset'\n",
    "separate_LA_SA(src_path, save4D=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Validation / Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_LA_SA_validation(src_path, dest_path, save4D=True):\n",
    "    \"\"\"\n",
    "    Segregate the splits into LA and SA views and dump all files in a common folder\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(dest_path, 'SA', 'final_test')):\n",
    "        shutil.rmtree(os.path.join(dest_path, 'SA', 'final_test'))\n",
    "    os.makedirs(os.path.join(dest_path, 'SA', 'final_test'))\n",
    "    patient_folders = next(os.walk(src_path))[1]\n",
    "    for patient in tqdm(patient_folders):\n",
    "        folder_path = os.path.join(src_path, patient)\n",
    "        img_file_path_list = glob.glob(folder_path + \"/*_SA*_ph*.dcm\")\n",
    "        imd_4d, pixel_spacing = get_4D_volume(img_file_path_list)\n",
    "        pixel_spacing += (1,) \n",
    "        c, r = extract_roi(imd_4d, pixel_spacing)\n",
    "        print (folder_path, imd_4d.shape, (c,r))\n",
    "#         To Save as 4D-volumes\n",
    "        if save4D:\n",
    "            hp = h5py.File(os.path.join(dest_path, 'SA', 'final_test', patient+'.hdf5'),'w')\n",
    "            hp.create_dataset('image', data=imd_4d)\n",
    "            hp.create_dataset('roi_center', data=c)\n",
    "            hp.create_dataset('roi_radii', data=r)\n",
    "            hp.create_dataset('pixel_spacing', data=pixel_spacing)                \n",
    "            hp.close()\n",
    "        else:                \n",
    "#         To Save as 2D images\n",
    "            _, _, slice_n, phase_n = imd_4d.shape\n",
    "            for slice in range(slice_n):\n",
    "                for phase in range(phase_n):                \n",
    "                    hp = h5py.File(os.path.join(dest_path, 'SA', 'final_test',\n",
    "                                                patient+\"_SA\"+str(slice)+\"_ph\"+str(phase)+'.hdf5'),'w')\n",
    "                    hp.create_dataset('image', data=imd_4d[:,:,slice, phase])\n",
    "                    hp.create_dataset('roi_center', data=c)\n",
    "                    hp.create_dataset('roi_radii', data=r)\n",
    "                    hp.create_dataset('pixel_spacing', data=pixel_spacing)   \n",
    "                    hp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<03:57,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('../../LV_2011_dataset/Validation/DET0026601', (192, 192, 11, 25), ((97, 100), (23, 22)))\n",
      "('../../LV_2011_dataset/Validation/DET0043001', (192, 156, 13, 25), ((100, 83), (22, 25)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:04<03:55,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0023601', (192, 192, 18, 25), ((91, 108), (29, 34)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:08<04:40,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0011701', (256, 256, 11, 20), ((122, 127), (33, 32)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:12<04:50,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0026101', (192, 192, 16, 25), ((105, 107), (39, 39)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:15<05:01,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0008001', (256, 232, 12, 25), ((119, 107), (31, 31)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:19<05:21,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0044001', (256, 192, 12, 27), ((133, 102), (30, 32)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:23<05:21,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0014001', (192, 144, 15, 20), ((102, 71), (27, 29)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [00:25<04:46,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0015001', (256, 256, 16, 20), ((123, 128), (31, 34)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:30<05:25,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0029901', (192, 180, 11, 25), ((96, 87), (26, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [00:32<04:43,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0026701', (192, 174, 11, 25), ((106, 81), (26, 27)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [00:34<04:17,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0012401', (192, 144, 13, 25), ((96, 73), (24, 25)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [00:37<04:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010201', (512, 512, 15, 20), ((258, 268), (39, 42)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [01:00<12:49,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0012201', (256, 256, 10, 25), ((135, 130), (39, 37)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [01:03<10:23,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0013001', (256, 256, 14, 20), ((135, 126), (25, 28)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [01:08<09:02,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0044101', (256, 224, 14, 19), ((140, 121), (33, 36)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [01:12<07:57,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0044501', (256, 216, 12, 21), ((131, 117), (29, 29)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [01:15<06:48,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0008701', (256, 256, 13, 19), ((127, 129), (35, 38)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [01:19<06:35,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0021301', (192, 192, 13, 25), ((90, 104), (24, 25)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [01:22<05:39,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0015801', (138, 192, 18, 25), ((57, 109), (23, 21)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [01:25<05:11,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0012901', (256, 256, 12, 20), ((124, 128), (31, 33)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [01:29<05:05,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0012001', (192, 156, 12, 25), ((94, 60), (26, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [01:31<04:26,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0021401', (256, 200, 11, 24), ((129, 106), (30, 31)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [01:34<04:10,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0029301', (192, 156, 13, 25), ((97, 77), (23, 23)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [01:37<03:46,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0014801', (256, 256, 14, 19), ((124, 126), (34, 33)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [01:42<04:29,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0013401', (256, 256, 12, 20), ((125, 139), (35, 36)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [01:46<04:34,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010801', (512, 512, 12, 25), ((253, 249), (59, 58)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [02:09<11:45,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0000901', (192, 138, 16, 25), ((92, 56), (24, 29)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [02:17<10:55,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010701', (512, 512, 14, 20), ((252, 253), (48, 49)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [02:42<16:17, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0015701', (256, 192, 11, 23), ((124, 108), (32, 32)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [02:48<13:18, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0044901', (256, 192, 10, 23), ((128, 101), (34, 36)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [02:51<10:25,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0027901', (192, 156, 9, 25), ((99, 72), (22, 25)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [02:54<08:11,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0012501', (256, 208, 11, 25), ((125, 103), (26, 27)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [02:58<07:01,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0011501', (256, 256, 11, 20), ((128, 119), (26, 23)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [03:03<06:19,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0023801', (240, 240, 17, 30), ((116, 110), (30, 34)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [03:12<07:22,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0019501', (256, 216, 13, 20), ((133, 123), (32, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [03:17<06:49,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0044701', (256, 216, 15, 20), ((127, 120), (30, 33)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [03:23<06:25,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0009501', (256, 192, 11, 22), ((134, 105), (34, 29)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [03:27<05:36,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0011401', (512, 512, 16, 20), ((232, 274), (39, 37)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [03:57<13:09, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0043301', (192, 156, 9, 25), ((95, 73), (24, 23)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [04:00<10:01, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0017401', (192, 162, 14, 25), ((104, 57), (26, 22)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [04:05<08:23,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0007401', (192, 192, 13, 30), ((96, 89), (34, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [04:10<07:06,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0007501', (192, 192, 12, 30), ((99, 100), (36, 34)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [04:15<06:11,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0000601', (192, 144, 8, 24), ((106, 49), (23, 23)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [04:18<05:07,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0014701', (192, 156, 10, 25), ((93, 92), (28, 28)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [04:21<04:31,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0042301', (192, 192, 11, 25), ((95, 84), (22, 21)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [04:26<04:27,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0035301', (512, 512, 13, 20), ((246, 264), (44, 44)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [04:51<09:30, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0020201', (512, 512, 15, 20), ((236, 256), (59, 57)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [05:17<13:23, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0014401', (256, 256, 11, 20), ((140, 96), (28, 27)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [05:21<10:15, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0025001', (192, 156, 9, 25), ((100, 76), (22, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [05:24<07:40,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010401', (512, 512, 13, 20), ((261, 258), (43, 39)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [05:48<11:12, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0026201', (256, 256, 12, 30), ((128, 125), (40, 37)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [05:57<09:48, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0015301', (192, 192, 14, 25), ((109, 97), (22, 24)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [06:02<07:49,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0007301', (192, 144, 14, 30), ((89, 69), (28, 25)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [06:09<07:02,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0000301', (192, 192, 16, 30), ((90, 104), (31, 34)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [06:15<06:12,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0008601', (256, 256, 14, 19), ((120, 122), (37, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [06:22<05:48,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0013101', (288, 288, 11, 20), ((143, 159), (29, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [06:28<05:08,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0042901', (192, 192, 12, 25), ((93, 93), (25, 25)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [06:31<04:13,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0011801', (256, 256, 14, 25), ((122, 131), (31, 33)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [06:40<04:42,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010001', (256, 256, 12, 20), ((122, 125), (23, 24)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [06:46<04:22,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0015501', (256, 208, 13, 28), ((128, 100), (29, 30)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [06:52<04:11,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0009201', (232, 256, 11, 24), ((118, 134), (30, 30)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [06:57<03:47,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0012101', (256, 256, 14, 20), ((121, 120), (28, 32)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [07:04<03:51,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0007601', (192, 192, 13, 25), ((98, 113), (31, 31)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [07:08<03:26,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0007701', (192, 192, 18, 25), ((108, 89), (41, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [07:14<03:24,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0009701', (192, 192, 15, 30), ((103, 128), (27, 27)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [07:21<03:30,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0014501', (256, 256, 16, 20), ((125, 123), (20, 20)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [07:29<03:35,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0009101', (256, 192, 10, 22), ((126, 108), (27, 27)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [07:32<03:00,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0000701', (192, 156, 11, 25), ((100, 66), (23, 24)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [07:36<02:41,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0014901', (256, 256, 14, 19), ((126, 126), (28, 29)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [07:44<02:54,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0011301', (512, 512, 14, 20), ((249, 266), (53, 45)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [08:10<05:46, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0042701', (192, 192, 11, 25), ((87, 97), (22, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [08:13<04:20,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0042201', (192, 156, 9, 25), ((90, 63), (25, 31)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [08:16<03:22,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0011601', (256, 256, 14, 28), ((155, 88), (35, 34)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [08:25<03:27,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0012601', (192, 156, 15, 25), ((95, 79), (24, 21)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [08:30<02:54,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0015101', (256, 256, 14, 20), ((124, 114), (38, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [08:36<02:41,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0019301', (192, 192, 14, 25), ((101, 90), (32, 32)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [08:40<02:16,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0007901', (288, 288, 18, 30), ((132, 139), (41, 36)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [08:55<03:10,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010501', (256, 256, 14, 20), ((125, 139), (23, 27)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [09:02<02:50,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0045401', (256, 152, 10, 23), ((126, 76), (27, 33)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [09:05<02:14,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0000401', (192, 192, 17, 30), ((87, 99), (34, 34)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [09:13<02:12,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0024301', (192, 192, 9, 25), ((92, 100), (26, 32)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [09:17<01:51,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0013301', (256, 256, 9, 20), ((131, 138), (33, 36)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [09:22<01:34,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0027601', (192, 156, 8, 25), ((86, 72), (25, 25)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [09:24<01:13,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0009401', (256, 208, 12, 20), ((129, 116), (33, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [09:28<01:07,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0019401', (232, 256, 12, 28), ((98, 127), (34, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [09:35<01:14,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010901', (256, 256, 11, 20), ((127, 131), (32, 30)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [09:40<01:06,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0029201', (180, 192, 12, 25), ((87, 94), (26, 27)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [09:46<01:04,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0043801', (256, 224, 12, 23), ((130, 124), (35, 33)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [09:53<01:05,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0030301', (192, 156, 10, 25), ((87, 70), (24, 28)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [09:56<00:51,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0014601', (256, 256, 9, 27), ((122, 129), (30, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [10:01<00:45,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0011201', (288, 288, 12, 24), ((141, 139), (34, 35)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [10:09<00:47,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0008301', (256, 256, 13, 20), ((129, 128), (24, 22)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [10:14<00:39,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0013801', (256, 256, 15, 25), ((128, 124), (28, 29)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [10:23<00:38,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0029601', (192, 156, 10, 25), ((108, 72), (25, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [10:25<00:26,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0007801', (256, 256, 10, 30), ((128, 125), (35, 36)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [10:31<00:22,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0009901', (192, 156, 9, 25), ((82, 61), (22, 26)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [10:34<00:13,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0008501', (256, 256, 12, 19), ((126, 128), (29, 28)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [10:39<00:09,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0016701', (512, 512, 14, 20), ((245, 257), (43, 46)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [11:04<00:10, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('../../LV_2011_dataset/Validation/DET0010301', (256, 200, 11, 30), ((126, 88), (30, 30)))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 100/100 [11:10<00:00,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Validation_data_path = '../../LV_2011_dataset/Validation'\n",
    "dest_path = '../../processed_dataset/dataset'\n",
    "separate_LA_SA_validation(Validation_data_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
